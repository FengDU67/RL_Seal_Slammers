"""
è¿ç»­åŠ¨ä½œç©ºé—´ç‰ˆæœ¬çš„Seal Slammersç¯å¢ƒ - V2ç‰ˆæœ¬
ä½¿ç”¨Softmaxé€‰æ‹©æ›¿ä»£ç¡¬æ˜ å°„ï¼Œè§£å†³æ¢¯åº¦ä¼ æ’­é—®é¢˜
"""

import math
import numpy as np
import gymnasium as gym
from gymnasium import spaces
import pygame
import random

# å®šä¹‰å¸¸é‡ï¼ˆä»åŸç¯å¢ƒå¤åˆ¶ï¼‰
SCREEN_WIDTH = 1000
SCREEN_HEIGHT = 600
OBJECT_RADIUS = 23
DEFAULT_HP_RANGE = (35, 50)
DEFAULT_ATK_RANGE = (7, 10)
NUM_OBJECTS_PER_PLAYER = 3
MAX_LAUNCH_STRENGTH_RL = 20.0
FORCE_MULTIPLIER = 0.08 * 4
FRICTION = 0.98
MIN_SPEED_THRESHOLD = 0.1
ELASTICITY = 1.0
MAX_PULL_RADIUS_MULTIPLIER = 4.0
MAX_VICTORY_POINTS = 5
DAMAGE_COOLDOWN_FRAMES = 10
HP_BAR_WIDTH = 40
HP_BAR_HEIGHT = 5

# é¢œè‰²å¸¸é‡
BLACK = (0, 0, 0)
WHITE = (255, 255, 255)
RED = (255, 0, 0)
BLUE = (0, 0, 255)
GREEN = (0, 255, 0)
GREY = (128, 128, 128)
LIGHT_GREY = (200, 200, 200)

# ä»åŸç¯å¢ƒå¯¼å…¥ç±»
from rl_seal_slammers.envs.seal_slammers_env import GameObject, Game

class SealSlammersEnvContinuousV2(gym.Env):
    """
    è¿ç»­åŠ¨ä½œç©ºé—´ç‰ˆæœ¬çš„Seal Slammersç¯å¢ƒ - V2
    åŠ¨ä½œç©ºé—´: Box(3) - [unit_selection, angle, strength]
    ä½¿ç”¨Softmaxé€‰æ‹©è§£å†³æ¢¯åº¦ä¼ æ’­é—®é¢˜
    """
    
    metadata = {"render_modes": ["human", "rgb_array"], "render_fps": 60}
    
    def __init__(self, render_mode=None, num_objects_per_player=NUM_OBJECTS_PER_PLAYER,
                 p0_hp_fixed=None, p0_atk_fixed=None,
                 p1_hp_fixed=None, p1_atk_fixed=None,
                 hp_range=DEFAULT_HP_RANGE,
                 atk_range=DEFAULT_ATK_RANGE,
                 temperature=1.0):  # æ–°å¢æ¸©åº¦å‚æ•°
        
        super().__init__()
        
        self.render_mode = render_mode
        self.num_objects_per_player = num_objects_per_player
        self.temperature = temperature  # Softmaxæ¸©åº¦å‚æ•°
        
        # HP/ATK configuration
        self.p0_hp_fixed = p0_hp_fixed
        self.p0_atk_fixed = p0_atk_fixed
        self.p1_hp_fixed = p1_hp_fixed
        self.p1_atk_fixed = p1_atk_fixed
        self.hp_range = hp_range
        self.atk_range = atk_range
        
        self.last_opponent_action = [-1.0, -1.0, -1.0]
        self.consecutive_meaningless_actions = 0
        
        # è¿ç»­åŠ¨ä½œç©ºé—´: [unit_selection, angle, strength]
        self.action_space = spaces.Box(
            low=0.0, high=1.0, shape=(3,), dtype=np.float32
        )
        
        # è§‚å¯Ÿç©ºé—´ä¿æŒä¸å˜
        obs_dim = (num_objects_per_player * 2 * 5) + 1 + 2 + 3
        self.observation_space = spaces.Box(
            low=-np.inf, high=np.inf, shape=(obs_dim,), dtype=np.float32
        )
        
        # åˆå§‹åŒ–pygameï¼ˆå¦‚æœéœ€è¦æ¸²æŸ“ï¼‰
        if render_mode == "human":
            pygame.init()
            self.screen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))
            pygame.display.set_caption("Seal Slammers - Continuous V2 (Softmax)")
            self.clock = pygame.time.Clock()
        else:
            self.screen = None
            self.clock = None
        
        # æ¸¸æˆå®ä¾‹
        self.game = None
    
    def _softmax_unit_selection(self, action_value, available_units):
        """
        ä½¿ç”¨Softmaxè¿›è¡Œå¯å¾®åˆ†çš„å•ä½é€‰æ‹©
        
        Args:
            action_value: è¿ç»­åŠ¨ä½œå€¼ [0, 1]
            available_units: å¯ç”¨å•ä½ç´¢å¼•åˆ—è¡¨
            
        Returns:
            selected_unit_idx: é€‰æ‹©çš„å•ä½ç´¢å¼•
            selection_probs: é€‰æ‹©æ¦‚ç‡åˆ†å¸ƒï¼ˆç”¨äºåˆ†æï¼‰
        """
        if not available_units:
            return 0, []
        
        n_units = len(available_units)
        
        # æ–¹æ³•1: åŸºäºè·ç¦»çš„logitsç”Ÿæˆ
        logits = np.zeros(n_units)
        target_pos = action_value * (n_units - 1)  # ç›®æ ‡ä½ç½®
        
        for i in range(n_units):
            # è®¡ç®—è·ç¦»ï¼Œè·ç¦»è¶Šè¿‘logitè¶Šå¤§
            distance = abs(i - target_pos)
            logits[i] = -distance / self.temperature
        
        # Softmaxè½¬æ¢ä¸ºæ¦‚ç‡
        exp_logits = np.exp(logits - np.max(logits))  # æ•°å€¼ç¨³å®šæ€§
        probs = exp_logits / np.sum(exp_logits)
        
        # æŒ‰æ¦‚ç‡é‡‡æ ·
        selected_idx = np.random.choice(n_units, p=probs)
        selected_unit_idx = available_units[selected_idx]
        
        return selected_unit_idx, probs
    
    def _alternative_softmax_unit_selection(self, action_value, available_units):
        """
        å¤‡é€‰æ–¹æ¡ˆï¼šç›´æ¥åŸºäºaction_valueç”Ÿæˆåå¥½
        
        è¿™ç§æ–¹æ³•æ›´ç›´æ¥ï¼Œæ™ºèƒ½ä½“çš„åå¥½æ›´æ˜ç¡®
        """
        if not available_units:
            return 0, []
        
        n_units = len(available_units)
        
        # æ–¹æ³•2: ç›´æ¥åŸºäºä½ç½®åå¥½
        logits = np.zeros(n_units)
        
        for i in range(n_units):
            # å°†æ¯ä¸ªå•ä½æ˜ å°„åˆ°[0,1]åŒºé—´
            unit_pos = i / max(1, n_units - 1) if n_units > 1 else 0.5
            # åŸºäºä¸action_valueçš„ç›¸ä¼¼åº¦ç”Ÿæˆlogit
            similarity = 1.0 - abs(unit_pos - action_value)
            logits[i] = similarity / self.temperature
        
        # Softmax
        exp_logits = np.exp(logits - np.max(logits))
        probs = exp_logits / np.sum(exp_logits)
        
        # é‡‡æ ·
        selected_idx = np.random.choice(n_units, p=probs)
        selected_unit_idx = available_units[selected_idx]
        
        return selected_unit_idx, probs
    
    def reset(self, seed=None, options=None):
        super().reset(seed=seed)
        
        if self.game:
            self.game.close()
        
        # åˆå§‹åŒ–æ¸¸æˆ
        self.game = Game(
            headless=(self.render_mode != "human" and self.render_mode != "rgb_array"),
            num_objects_per_player=self.num_objects_per_player
        )
        
        # è®¾ç½®HPå’Œæ”»å‡»åŠ›
        import random
        p0_hp = self.p0_hp_fixed if self.p0_hp_fixed is not None else random.uniform(self.hp_range[0], self.hp_range[1])
        p0_atk = self.p0_atk_fixed if self.p0_atk_fixed is not None else random.uniform(self.atk_range[0], self.atk_range[1])
        p1_hp = self.p1_hp_fixed if self.p1_hp_fixed is not None else random.uniform(self.hp_range[0], self.hp_range[1])
        p1_atk = self.p1_atk_fixed if self.p1_atk_fixed is not None else random.uniform(self.atk_range[0], self.atk_range[1])
        
        self.game.reset_game_state(p0_hp=p0_hp, p0_atk=p0_atk, p1_hp=p1_hp, p1_atk=p1_atk)
        
        self.last_opponent_action = [-1.0, -1.0, -1.0]
        self.consecutive_meaningless_actions = 0
        
        obs = self._get_obs()
        info = {}
        
        return obs, info
    
    def step(self, action):
        """
        å¤„ç†è¿ç»­åŠ¨ä½œå¹¶ä½¿ç”¨Softmaxé€‰æ‹©
        action: [unit_selection, angle, strength] å‡åœ¨ [0, 1] èŒƒå›´å†…
        """
        # è§£æè¿ç»­åŠ¨ä½œ
        unit_selection_raw, angle_raw, strength_raw = action
        
        current_player_id = self.game.current_player_turn
        
        # è·å–å¯ç”¨å•ä½
        available_units = []
        player_objects = self.game.players_objects[current_player_id]
        for i, obj in enumerate(player_objects):
            if obj.hp > 0 and not obj.has_moved_this_turn:
                available_units.append(i)
        
        if not available_units:
            # æ²¡æœ‰å¯ç”¨å•ä½æ—¶çš„å¤„ç†
            selected_obj = None
            object_idx = 0
            angle_rad = 0
            strength = 0
            attempted_to_select_moved_object = False
            is_invalid_action = True
            selection_probs = []
        else:
            # ğŸ¯ å…³é”®æ”¹è¿›ï¼šä½¿ç”¨Softmaxé€‰æ‹©æ›¿ä»£ç¡¬æ˜ å°„
            object_idx, selection_probs = self._softmax_unit_selection(
                unit_selection_raw, available_units
            )
            selected_obj = player_objects[object_idx]
            
            # è§’åº¦æ˜ å°„ï¼šå°† [0, 1] æ˜ å°„åˆ° [0, 2Ï€]
            angle_rad = angle_raw * 2 * math.pi
            
            # åŠ›åº¦æ˜ å°„ï¼šé™åˆ¶æœ€å°åŠ›åº¦ï¼Œé¿å…æ— æ„ä¹‰çš„å¾®å¼±æ”»å‡»
            min_strength = 0.1  # æœ€å°åŠ›åº¦é˜ˆå€¼
            strength = max(min_strength, strength_raw)
            
            attempted_to_select_moved_object = False
            is_invalid_action = False
        
        # è®°å½•åˆå§‹çŠ¶æ€ç”¨äºå¥–åŠ±è®¡ç®—
        initial_scores = list(self.game.scores)
        initial_hp_states = []
        for p_objs in self.game.players_objects:
            initial_hp_states.append([obj.hp for obj in p_objs])
        
        # æ‰§è¡ŒåŠ¨ä½œ
        if selected_obj:
            # è®¡ç®—å‘å°„è§’åº¦ï¼ˆä¸æ‹‰æ‹½æ–¹å‘ç›¸åï¼‰
            launch_angle_rad = angle_rad + math.pi
            selected_obj.angle = launch_angle_rad
            
            # è®¡ç®—å®é™…åŠ›åº¦
            actual_strength_magnitude = strength * MAX_LAUNCH_STRENGTH_RL
            
            # è®¡ç®—é€Ÿåº¦åˆ†é‡
            launch_vx = math.cos(launch_angle_rad) * actual_strength_magnitude
            launch_vy = math.sin(launch_angle_rad) * actual_strength_magnitude
            
            # è®¡ç®—éœ€è¦ä¼ é€’ç»™apply_forceçš„å‚æ•°
            if FORCE_MULTIPLIER == 0:
                dx_to_pass = 0
                dy_to_pass = 0
            else:
                dx_to_pass = -launch_vx / FORCE_MULTIPLIER
                dy_to_pass = -launch_vy / FORCE_MULTIPLIER
            
            selected_obj.apply_force(dx_to_pass, dy_to_pass)
            self.game.action_processing_pending = True
            
            # è®°å½•åŠ¨ä½œï¼ˆç”¨äºè§‚å¯Ÿï¼‰
            action_taken = [float(object_idx), angle_raw, strength_raw]
        else:
            # æ— æ•ˆåŠ¨ä½œ
            self.game.action_processing_pending = True
            action_taken = [0.0, angle_raw, strength_raw]
        
        # æ¨¡æ‹Ÿç‰©ç†è¿‡ç¨‹
        frames_this_step = 0
        MAX_FRAMES_PER_ACTION_STEP = 300
        
        while self.game.action_processing_pending and frames_this_step < MAX_FRAMES_PER_ACTION_STEP:
            still_active = self.game._simulate_frame_physics_and_damage()
            if not still_active:
                self.game.action_processing_pending = False
            
            frames_this_step += 1
            
            if self.render_mode == "human":
                self.render()
            
            if self.game.game_over:
                break
        
        self.game.action_processing_pending = False
        
        terminated = self.game.game_over
        
        # è®¡ç®—å¥–åŠ±
        reward = self._calculate_reward(
            initial_scores, initial_hp_states, selected_obj, 
            terminated, current_player_id
        )
        
        # é¢å¤–æƒ©ç½šï¼ˆå¦‚æœå°è¯•é€‰æ‹©å·²ç§»åŠ¨çš„å¯¹è±¡ï¼‰
        if attempted_to_select_moved_object:
            reward -= 10.0
        
        # é‡ç”Ÿè¢«å‡»è´¥çš„å¯¹è±¡
        if not terminated:
            for player_list_idx, player_objs in enumerate(self.game.players_objects):
                for obj_to_respawn in player_objs:
                    if obj_to_respawn.hp <= 0:
                        preferred_x = obj_to_respawn.original_x
                        preferred_y = obj_to_respawn.original_y
                        
                        final_x, final_y = self.game._find_non_overlapping_spawn_position(
                            obj_to_respawn, preferred_x, preferred_y
                        )
                        
                        obj_to_respawn.respawn(final_x, final_y)
        
        # æ›´æ–°å›åˆ
        if not self.game.action_processing_pending:
            self._handle_turn_progression()
        
        # æ›´æ–°å¯¹æ‰‹åŠ¨ä½œè®°å½•
        if self.game.current_player_turn != current_player_id:
            self.last_opponent_action = action_taken
        
        obs = self._get_obs()
        info = {
            'scores': self.game.scores,
            'current_player': self.game.current_player_turn,
            'action_taken': action_taken,
            'selected_object': object_idx if selected_obj else None,
            'selection_probs': selection_probs.tolist() if len(selection_probs) > 0 else [],
            'available_units': available_units,
            'softmax_temperature': self.temperature
        }
        
        return obs, reward, terminated, False, info
    
    def _get_obs(self):
        """è·å–è§‚å¯ŸçŠ¶æ€ï¼ˆä¸åŸç¯å¢ƒç›¸åŒï¼‰"""
        state = []
        
        # è®¡ç®—å±å¹•ä¸­å¿ƒç”¨äºç›¸å¯¹ä½ç½®è®¡ç®—
        center_x = SCREEN_WIDTH / 2
        center_y = SCREEN_HEIGHT / 2
        
        # å¯¹è±¡ç‰¹å¾ï¼ˆä½¿ç”¨ç›¸å¯¹ä½ç½®ï¼‰
        for player_objs in self.game.players_objects:
            for obj in player_objs:
                # ç›¸å¯¹ä½ç½®ï¼ˆå½’ä¸€åŒ–åˆ° [-1, 1]ï¼‰
                rel_x = (obj.x - center_x) / (SCREEN_WIDTH / 2)
                rel_y = (obj.y - center_y) / (SCREEN_HEIGHT / 2)
                
                # å½’ä¸€åŒ–HPå’Œæ”»å‡»åŠ›
                norm_hp = obj.hp / 100.0
                norm_attack = obj.attack / 20.0
                
                # ç§»åŠ¨çŠ¶æ€
                has_moved = 1.0 if obj.has_moved_this_turn else 0.0
                
                state.extend([rel_x, rel_y, norm_hp, norm_attack, has_moved])
        
        # å½“å‰ç©å®¶å›åˆ
        state.append(float(self.game.current_player_turn))
        
        # å½’ä¸€åŒ–åˆ†æ•°
        state.extend([self.game.scores[0] / 10.0, self.game.scores[1] / 10.0])
        
        # ä¸Šä¸€ä¸ªå¯¹æ‰‹åŠ¨ä½œï¼ˆå·²ç»æ˜¯å½’ä¸€åŒ–çš„ï¼‰
        state.extend(self.last_opponent_action)
        
        return np.array(state, dtype=np.float32)
    
    def _calculate_reward(self, initial_scores, initial_hp_states, selected_obj, 
                         terminated, current_player_id):
        """è®¡ç®—å¥–åŠ±ï¼ˆä¸åŸç¯å¢ƒç›¸åŒçš„é€»è¾‘ï¼‰"""
        reward = 0.0
        
        # åˆ†æ•°å¥–åŠ±
        score_diff = self.game.scores[current_player_id] - initial_scores[current_player_id]
        reward += score_diff * 100.0
        
        # ä¼¤å®³å¥–åŠ±
        for player_idx, player_objs in enumerate(self.game.players_objects):
            for obj_idx, obj in enumerate(player_objs):
                initial_hp = initial_hp_states[player_idx][obj_idx]
                current_hp = obj.hp
                hp_lost = initial_hp - current_hp
                
                if hp_lost > 0:
                    if player_idx == current_player_id:
                        # å·±æ–¹å—ä¼¤ï¼Œæƒ©ç½š
                        reward -= hp_lost * 2.0
                    else:
                        # å¯¹æ‰‹å—ä¼¤ï¼Œå¥–åŠ±
                        reward += hp_lost * 2.0
        
        # æ— æ•ˆåŠ¨ä½œæƒ©ç½š
        if selected_obj is None:
            reward -= 50.0
        
        # ç»ˆå±€å¥–åŠ±
        if terminated:
            if self.game.scores[current_player_id] > self.game.scores[1 - current_player_id]:
                reward += 200.0  # èƒœåˆ©å¥–åŠ±
            else:
                reward -= 200.0  # å¤±è´¥æƒ©ç½š
        
        return reward
    
    def _handle_turn_progression(self):
        """å¤„ç†å›åˆè¿›å±•é€»è¾‘ï¼ˆä»åŸç¯å¢ƒå¤åˆ¶ï¼‰"""
        player_who_just_moved = self.game.current_player_turn
        potential_next_player = 1 - player_who_just_moved

        can_potential_next_player_move = self.game.can_player_move(potential_next_player)
        can_player_who_just_moved_still_move = self.game.can_player_move(player_who_just_moved)

        if can_potential_next_player_move:
            self.game.current_player_turn = potential_next_player
        elif can_player_who_just_moved_still_move:
            # å½“å‰ç©å®¶ç»§ç»­è¡ŒåŠ¨
            pass
        else:
            # åŒæ–¹éƒ½ä¸èƒ½ç§»åŠ¨ï¼Œå¼€å§‹æ–°å›åˆ
            self.game.next_round()
    
    def render(self):
        """æ¸²æŸ“æ¸¸æˆç”»é¢"""
        if self.render_mode == "human" and self.screen:
            self.game.render(self.screen)
            pygame.display.flip()
            self.clock.tick(60)
    
    def close(self):
        """å…³é—­ç¯å¢ƒ"""
        if self.game and hasattr(self.game, 'close'):
            self.game.close()
        if self.screen:
            pygame.quit()
